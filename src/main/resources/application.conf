akka.persistence.journal.plugin = "cassandra-journal"

akka.actor.warn-about-java-serializer-usage = false

cassandra-journal {
    event-adapters {
      tagging = "poc.persistence.write.OrderTaggingEventAdapter"
    }

    event-adapter-bindings {
      "poc.persistence.events.OrderInitialized" = tagging
      "poc.persistence.events.OrderCancelled" = tagging
    }
}


akka {
  actor {
    provider = "akka.cluster.ClusterActorRefProvider"

    serializers {
      json = "poc.persistence.write.EventSerialization"
    }

    serialization-bindings {
      "poc.persistence.events.OrderCancelled" = json
      "poc.persistence.events.OrderInitialized" = json
      "poc.persistence.read.user.events.UserInitializedOrder" = json
      "poc.persistence.read.user.events.UserCancelledOrder" = json
      "poc.persistence.read.streammanager.events.ProgressAcknowledged" = json
    }

  }

  remote {
    log-remote-lifecycle-events = off
    netty.tcp {
      hostname = ${clustering.ip}
      port = ${clustering.port}
    }
  }

  logger-startup-timeout = 10s

  // don't do this for production
  log-dead-letters = 0
  log-dead-letters-during-shutdown = off

  loggers = ["akka.event.slf4j.Slf4jLogger"]
  loglevel = "INFO"
  logging-filter = "akka.event.slf4j.Slf4jLoggingFilter"

  cluster {
    seed-nodes = [
      "akka.tcp://example@"${clustering.ip}":2551"
    ]
    sharding.state-store-mode = ddata
  }

  extensions = ["akka.cluster.ddata.DistributedData"]
}

clustering {
  ip = "127.0.0.1"
  port = 2551
}

web {
  port = 8080
}

akka.cluster.downing-provider-class = "com.lightbend.akka.sbr.SplitBrainResolverProvider"

akka.cluster.auto-down-unreachable-after = off

akka.cluster.split-brain-resolver.active-strategy=static-quorum

akka.cluster.split-brain-resolver {
  stable-after = 7s
}

akka.cluster.split-brain-resolver.static-quorum.quorum-size = 2


akka.cluster.http.management.hostname = ${management.ip}
akka.cluster.http.management.port = ${management.port}